# Universal metrics configuration
# All metrics work with any dataset - no dataset-specific restrictions

# Available metrics (all dataset-agnostic):
available_metrics:
  - "accuracy"      # Fraction of queries with relevant result at rank 1
  - "recall@1"      # Fraction of queries with ≥1 relevant in top-1 (same as accuracy)
  - "recall@4"      # Fraction of queries with ≥1 relevant in top-4  
  - "recall@10"     # Fraction of queries with ≥1 relevant in top-10
  - "precision@10"  # Average precision in top-10 results
  - "map"           # Mean Average Precision (full)
  - "map@10"        # Mean Average Precision at 10
  - "map@50"        # Mean Average Precision at 50
  - "ns_score"      # Normalized Score (avg relevant in top-k)

# Example configurations for different use cases:

# Quick evaluation (fast metrics)
quick_metrics: [accuracy, recall@4, map@10]

# Standard evaluation (balanced)
standard_metrics: [accuracy, recall@4, recall@10, map@10, ns_score]

# Comprehensive evaluation (all metrics)
comprehensive_metrics: [accuracy, recall@1, recall@4, recall@10, precision@10, map, map@10, map@50, ns_score]

# UKBench traditional (for comparison with papers)
ukbench_traditional: [ns_score, recall@1, recall@4, map@10]

# Holidays traditional (for comparison with papers)  
holidays_traditional: [map, map@10, map@50, recall@1, recall@10, precision@10]

# Parameters:
k: 4  # For N-S score computation (can be any value)
