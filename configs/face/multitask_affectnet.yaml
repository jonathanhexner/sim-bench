# Multitask Face Pretraining Configuration
# Dataset: AffectNet
# Tasks: Expression Classification (8 classes) + Landmark Regression (5-10 points)
# Model: ResNet-50 with uncertainty weighting

# Reproducibility
seed: 42

# Device configuration
device: "cpu"  # or "cpu"

# Data configuration
data:
  train_dir: "D:/DataSets/AffectNet/train"
  val_dir: null  # Auto-split from train if null
  val_split: 0.2  # 10% for validation
  landmarks_cache: cache/affectnet_landmarks.json   # Pre-extracted landmarks (set path if available)
  num_workers: 0  # Use 0 on Windows to avoid multiprocessing segfaults

# Model configuration
model:
  backbone: "resnet50"  # or "resnet18"
  pretrained: true
  embedding_dim: 512
  num_expression_classes: 8  # AffectNet: 0=Neutral, 1=Happiness, 2=Sadness, 3=Surprise, 4=Fear, 5=Disgust, 6=Anger, 7=Contempt
  num_landmarks: 5  # 5 or 10 key points
  dropout: 0.0
  use_uncertainty_weighting: true  # Use learnable loss weighting

# Transform configuration
transform:
  input_size: 224
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]
  augmentation:
    horizontal_flip: 0.5
    color_jitter:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.05

# Training configuration
training:
  batch_size: 16  # Reduced from 64 for CPU training stability
  learning_rate: 0.001  # Lower than face recognition (easier task)
  differential_lr: true  # Backbone 1x, heads 10x
  optimizer: "adamw"  # AdamW often better for multitask
  weight_decay: 0.0001
  max_epochs: 30
  expression_weight: 1.0  # Only used if uncertainty_weighting=false
  landmark_weight: 1.0   # Only used if uncertainty_weighting=false

  # Learning rate schedule with warmup
  scheduler:
    type: "cosine"
    T_max: 30
    eta_min: 0.00001
    warmup_epochs: 1  # Gradually increase LR for first epoch

# Output configuration
output_dir: null  # Auto-generated if null
checkpoint_interval: 5

# Logging
log_interval: 100
