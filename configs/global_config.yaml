# Global Configuration for sim-bench
# This file contains settings that apply across all modules and experiments
# Individual experiment configs can override these settings

# ============================================================================
# Compute Resources
# ============================================================================
device: cpu  # Device for computation: 'cpu', 'cuda', 'cuda:0', 'cuda:1', 'mps'
num_workers: 4  # Number of parallel workers for CPU operations

# ============================================================================
# Directory Paths
# ============================================================================
output_dir: outputs/  # Default output directory for all results
cache_dir: .cache/    # Cache directory for embeddings, thumbnails, etc.
log_dir: logs/        # Directory for log files

# ============================================================================
# Caching Settings
# ============================================================================
enable_embedding_cache: true   # Cache vision-language model embeddings
enable_thumbnail_cache: true   # Cache generated thumbnails
enable_quality_cache: true     # Cache quality assessment scores
cache_max_size_gb: 10          # Maximum cache size in GB (automatic cleanup)

# ============================================================================
# Image Processing
# ============================================================================
thumbnail_sizes:
  tiny: 128      # For fast CLIP tagging and routing decisions
  small: 512     # For UI previews and quick browsing
  medium: 1024   # For quality assessment and composition analysis
  large: 2048    # For specialized models (face detection, etc.)

thumbnail_quality: 90  # JPEG quality for thumbnails (1-100)
thumbnail_format: jpg  # Thumbnail format: 'jpg' or 'png'

# ============================================================================
# Vision-Language Model Defaults
# ============================================================================
clip:
  model_name: ViT-B-32              # CLIP model architecture
  pretrained: laion2b_s34b_b79k     # Pretrained checkpoint
  batch_size: 32                     # Batch size for encoding
  enable_cache: true                 # Cache CLIP embeddings

# ============================================================================
# Quality Assessment
# ============================================================================
quality_assessment:
  default_method: clip_aesthetic  # Default quality method
  enable_cache: true              # Cache quality scores
  batch_size: 16                  # Batch size for assessment

# ============================================================================
# Photo Analysis
# ============================================================================
photo_analysis:
  use_thumbnails: true           # Use thumbnails for analysis (recommended)
  thumbnail_size: tiny           # Which thumbnail size to use for CLIP tagging
  routing_threshold: 0.6         # Confidence threshold for routing decisions
  importance_weights:            # Weights for computing importance score
    quality: 0.4                 # Quality assessment weight
    composition: 0.3             # Composition score weight
    uniqueness: 0.3              # Uniqueness/diversity weight

# ============================================================================
# Clustering
# ============================================================================
clustering:
  default_algorithm: hdbscan     # Default clustering algorithm
  min_cluster_size: 5            # Minimum photos per cluster
  normalize_features: true       # L2-normalize features before clustering

# ============================================================================
# Logging
# ============================================================================
logging:
  level: INFO                    # Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
  log_to_file: true              # Write logs to file
  log_to_console: true           # Print logs to console
  max_log_size_mb: 100           # Max log file size before rotation
  backup_count: 3                # Number of backup log files to keep

# ============================================================================
# Performance
# ============================================================================
performance:
  max_batch_size: 64             # Maximum batch size (memory constraint)
  prefetch_factor: 2             # Number of batches to prefetch
  pin_memory: false              # Pin memory for CUDA (set true if using GPU)
  persistent_workers: false      # Keep workers alive between epochs

# ============================================================================
# Export
# ============================================================================
export:
  default_format: html           # Default export format
  include_metadata: true         # Include metadata in exports
  copy_original_files: false     # Copy vs. symlink original files

# ============================================================================
# Album Organization
# ============================================================================
album:
  # Quality thresholds for filtering
  quality:
    min_iqa_score: 0.3           # Minimum technical quality (0-1)
    min_ava_score: 4.0           # Minimum aesthetic score (1-10)
    min_sharpness: 0.2           # Minimum sharpness (0-1)

  # Portrait preferences for selection
  portrait:
    require_eyes_open: true      # Filter out photos with closed eyes
    prefer_smiling: true         # Prefer smiling photos in selection
    smile_importance: 0.3        # Weight for smile in scoring (0-1)
    eyes_open_importance: 0.4    # Weight for eyes open in scoring (0-1)

  # Clustering settings
  clustering:
    method: hdbscan              # Clustering algorithm: 'hdbscan', 'dbscan', 'kmeans'
    feature_method: dinov2       # Feature extraction: 'dinov2', 'openclip', 'resnet50'
    min_cluster_size: 3          # Minimum photos per cluster

  # Best image selection
  selection:
    images_per_cluster: 1        # Number of images to select per cluster
    ava_weight: 0.5              # Weight for aesthetic score
    iqa_weight: 0.2              # Weight for technical quality
    portrait_weight: 0.3         # Weight for portrait metrics
    use_siamese_tiebreaker: true # Use Siamese model for close decisions

  # Export settings
  export:
    format: folder               # Export format: 'folder', 'zip'
    organize_by_cluster: true    # Organize output by cluster
    include_thumbnails: true     # Include thumbnails in export

# ============================================================================
# Portrait Analysis (MediaPipe)
# ============================================================================
portrait_analysis:
  face_detection_confidence: 0.5       # Minimum confidence for face detection
  portrait_face_ratio_threshold: 0.0005 # Min face area ratio for portrait
  portrait_center_offset_threshold: 0.3 # Max center offset for portrait
  eye_open_ear_threshold: 0.2          # Eye Aspect Ratio threshold
  smile_width_threshold: 0.15          # Mouth width ratio for smile
  smile_elevation_threshold: 0.005     # Corner elevation for smile
