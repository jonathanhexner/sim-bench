# 3-Hour Pairwise Benchmark Configuration
# Balanced sampling to evaluate all methods within time budget

dataset:
  pairs_file: "data/phototriage/pairs_train.jsonl"
  use_attributes: false

  # Sample 4000 pairs for 3-hour runtime
  # 4000 pairs * 8 methods * ~3.5 sec/pair = ~111 minutes + overhead = ~3 hours
  sampling:
    enabled: true
    num_pairs: 4000
    random_seed: 42

methods:
  # Rule-based methods (5 methods, ~20min total)
  - name: "Sharpness"
    type: "rule_based"
    weights:
      sharpness: 1.0
      exposure: 0.0
      colorfulness: 0.0
      contrast: 0.0

  - name: "Exposure"
    type: "rule_based"
    weights:
      sharpness: 0.0
      exposure: 1.0
      colorfulness: 0.0
      contrast: 0.0

  - name: "Contrast"
    type: "rule_based"
    weights:
      sharpness: 0.0
      exposure: 0.0
      colorfulness: 0.0
      contrast: 1.0

  - name: "Colorfulness"
    type: "rule_based"
    weights:
      sharpness: 0.0
      exposure: 0.0
      colorfulness: 1.0
      contrast: 0.0

  - name: "Combined-RuleBased"
    type: "rule_based"
    weights:
      sharpness: 0.4
      exposure: 0.3
      colorfulness: 0.2
      contrast: 0.1

  # CLIP methods (3 methods, ~2.5 hours total)
  # NOTE: Change device to "cuda" if you have GPU available
  - name: "CLIP-Aesthetic-LAION"
    type: "clip_aesthetic"
    variant: "laion"
    model_name: "ViT-B-32"
    device: "cpu"

  - name: "CLIP-Aesthetic-SAC"
    type: "clip_aesthetic"
    variant: "sac"
    model_name: "ViT-B-32"
    device: "cpu"

  - name: "CLIP-LearnedPrompts"
    type: "clip_aesthetic"
    variant: "learned"
    prompts_config: "configs/learned_aesthetic_prompts.yaml"
    device: "cpu"

output:
  base_dir: "outputs/pairwise_benchmark_3hour"
  create_timestamp_dir: true

execution:
  verbose: true
  log_level: "INFO"
