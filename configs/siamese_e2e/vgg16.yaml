# End-to-End VGG16 Siamese Network Training
# Fine-tunes entire VGG16 CNN backbone + MLP head
# Uses PhotoTriage paper preprocessing (aspect-ratio preserving + padding)

name: "siamese_e2e_vgg16"

data:
  root_dir: "D:\\Similar Images\\automatic_triage_photo_series"
  min_agreement: 0.7
  min_reviewers: 2
  split_mode: "series_based"
  quick_experiment: null  # Set to 0.1 for 10% of data

model:
  # Siamese CNN + MLP configuration
  cnn_backbone: "vgg16"
  pretrained: true
  use_paper_preprocessing: true  # Aspect-ratio preserving resize + padding
  padding_mean_color: [0.460, 0.450, 0.430]  # Mean pixel color from training set
  
  # MLP head architecture
  mlp_hidden_dims: [128, 128]
  dropout: 0.0
  activation: "tanh"

training:
  batch_size: 16  # Smaller batch size for memory constraints
  learning_rate: 0.001  # Paper uses 0.001 for VGG16
  optimizer: "sgd"
  momentum: 0.9
  weight_decay: 0.0005
  max_epochs: 30
  early_stop_patience: 5

output_dir: "outputs/siamese_e2e_vgg16"
device: "cpu"
seed: 42
log_interval: 10  # Log every N batches

