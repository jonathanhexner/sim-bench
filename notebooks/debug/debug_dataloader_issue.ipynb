{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "056300c8",
      "metadata": {},
      "source": [
        "# Dataloader Debugging Notebook\n",
        "\n",
        "Interactive analysis of internal vs external dataloader performance.\n",
        "\n",
        "**Purpose**: Diagnose why internal (51.8% acc) underperforms external (69.6% acc)\n",
        "\n",
        "**Experiments**:\n",
        "- Internal: `outputs/siamese_e2e/20260113_073023`\n",
        "- External: `outputs/siamese_e2e/20260111_005327`\n",
        "\n",
        "**Sections**:\n",
        "1. Training curves comparison\n",
        "2. Weight snapshot analysis\n",
        "3. Batch statistics\n",
        "4. Holdout predictions\n",
        "5. Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d43eaad",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "# Add project to path\n",
        "sys.path.insert(0, str(Path.cwd().parent))\n",
        "\n",
        "# Plotting setup\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Experiment paths\n",
        "INTERNAL_EXP = Path('../outputs/siamese_e2e/20260113_073023')\n",
        "EXTERNAL_EXP = Path('../outputs/siamese_e2e/20260111_005327')\n",
        "\n",
        "print(f\"Internal experiment: {INTERNAL_EXP.exists()}\")\n",
        "print(f\"External experiment: {EXTERNAL_EXP.exists()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3f6b8d1",
      "metadata": {},
      "source": [
        "## 1. Training Curves Comparison\n",
        "\n",
        "Compare loss and accuracy curves side-by-side."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ecb14d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training history\n",
        "with open(INTERNAL_EXP / 'training_history.json') as f:\n",
        "    internal_history = json.load(f)\n",
        "\n",
        "with open(EXTERNAL_EXP / 'training_history.json') as f:\n",
        "    external_history = json.load(f)\n",
        "\n",
        "# Plot training curves\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "epochs_internal = range(1, len(internal_history['train_loss']) + 1)\n",
        "epochs_external = range(1, len(external_history['train_loss']) + 1)\n",
        "\n",
        "# Train loss\n",
        "axes[0, 0].plot(epochs_internal, internal_history['train_loss'], 'b-o', label='Internal', linewidth=2)\n",
        "axes[0, 0].plot(epochs_external, external_history['train_loss'], 'r-s', label='External', linewidth=2)\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].set_title('Training Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Val loss\n",
        "axes[0, 1].plot(epochs_internal, internal_history['val_loss'], 'b-o', label='Internal', linewidth=2)\n",
        "axes[0, 1].plot(epochs_external, external_history['val_loss'], 'r-s', label='External', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].set_title('Validation Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Train acc\n",
        "axes[1, 0].plot(epochs_internal, internal_history['train_acc'], 'b-o', label='Internal', linewidth=2)\n",
        "axes[1, 0].plot(epochs_external, external_history['train_acc'], 'r-s', label='External', linewidth=2)\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "axes[1, 0].set_title('Training Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Val acc\n",
        "axes[1, 1].plot(epochs_internal, internal_history['val_acc'], 'b-o', label='Internal', linewidth=2)\n",
        "axes[1, 1].plot(epochs_external, external_history['val_acc'], 'r-s', label='External', linewidth=2)\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Accuracy (%)')\n",
        "axes[1, 1].set_title('Validation Accuracy')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "axes[1, 1].axhline(y=50, color='gray', linestyle='--', label='Random', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"Final Metrics:\")\n",
        "print(f\"  Internal: train_acc={internal_history['train_acc'][-1]:.1f}%, val_acc={internal_history['val_acc'][-1]:.1f}%\")\n",
        "print(f\"  External: train_acc={external_history['train_acc'][-1]:.1f}%, val_acc={external_history['val_acc'][-1]:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b4a59b",
      "metadata": {},
      "source": [
        "## 2. Gradient Norm Comparison\n",
        "\n",
        "Compare gradient norms to understand optimization dynamics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d60d65c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load gradient norms\n",
        "grad_internal = pd.read_csv(INTERNAL_EXP / 'telemetry' / 'gradient_norms.csv')\n",
        "grad_external = pd.read_csv(EXTERNAL_EXP / 'telemetry' / 'gradient_norms.csv')\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Overall gradient norm\n",
        "axes[0].plot(grad_internal.index, grad_internal['overall'], 'b-', alpha=0.7, label='Internal')\n",
        "axes[0].plot(grad_external.index, grad_external['overall'], 'r-', alpha=0.7, label='External')\n",
        "axes[0].set_xlabel('Collection Step')\n",
        "axes[0].set_ylabel('Gradient Norm')\n",
        "axes[0].set_title('Overall Gradient Norm')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Backbone gradient norm\n",
        "axes[1].plot(grad_internal.index, grad_internal['backbone'], 'b-', alpha=0.7, label='Internal')\n",
        "axes[1].plot(grad_external.index, grad_external['backbone'], 'r-', alpha=0.7, label='External')\n",
        "axes[1].set_xlabel('Collection Step')\n",
        "axes[1].set_ylabel('Gradient Norm')\n",
        "axes[1].set_title('Backbone Gradient Norm')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Head gradient norm\n",
        "axes[2].plot(grad_internal.index, grad_internal['head'], 'b-', alpha=0.7, label='Internal')\n",
        "axes[2].plot(grad_external.index, grad_external['head'], 'r-', alpha=0.7, label='External')\n",
        "axes[2].set_xlabel('Collection Step')\n",
        "axes[2].set_ylabel('Gradient Norm')\n",
        "axes[2].set_title('Head Gradient Norm')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Average gradient norms:\")\n",
        "print(f\"  Internal: overall={grad_internal['overall'].mean():.4f}, backbone={grad_internal['backbone'].mean():.4f}, head={grad_internal['head'].mean():.4f}\")\n",
        "print(f\"  External: overall={grad_external['overall'].mean():.4f}, backbone={grad_external['backbone'].mean():.4f}, head={grad_external['head'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddc44b6c",
      "metadata": {},
      "source": [
        "## 3. Batch Statistics\n",
        "\n",
        "Compare winner label distribution in training batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec7ef6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load batch stats\n",
        "batch_internal = pd.read_csv(INTERNAL_EXP / 'telemetry' / 'batch_stats.csv')\n",
        "batch_external = pd.read_csv(EXTERNAL_EXP / 'telemetry' / 'batch_stats.csv')\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Winner=1 percentage over time\n",
        "axes[0].plot(batch_internal.index, batch_internal['winner_1_pct'], 'b-', alpha=0.6, label='Internal')\n",
        "axes[0].plot(batch_external.index, batch_external['winner_1_pct'], 'r-', alpha=0.6, label='External')\n",
        "axes[0].axhline(y=50, color='gray', linestyle='--', label='Balanced (50%)', alpha=0.5)\n",
        "axes[0].set_xlabel('Collection Step')\n",
        "axes[0].set_ylabel('Winner=1 Percentage')\n",
        "axes[0].set_title('Batch Label Distribution Over Time')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Distribution histograms\n",
        "axes[1].hist(batch_internal['winner_1_pct'], bins=20, alpha=0.5, color='blue', label='Internal', edgecolor='black')\n",
        "axes[1].hist(batch_external['winner_1_pct'], bins=20, alpha=0.5, color='red', label='External', edgecolor='black')\n",
        "axes[1].axvline(x=50, color='gray', linestyle='--', label='Balanced', alpha=0.7)\n",
        "axes[1].set_xlabel('Winner=1 Percentage')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Distribution of Batch Label Balance')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Winner=1 percentage statistics:\")\n",
        "print(f\"  Internal: mean={batch_internal['winner_1_pct'].mean():.1f}%, std={batch_internal['winner_1_pct'].std():.1f}%\")\n",
        "print(f\"  External: mean={batch_external['winner_1_pct'].mean():.1f}%, std={batch_external['winner_1_pct'].std():.1f}%\")\n",
        "print(f\"\\nâš ï¸ External has {batch_external['winner_1_pct'].mean() - 50:.1f}% bias toward winner=1!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75b25e47",
      "metadata": {},
      "source": [
        "## 4. Holdout Predictions Analysis\n",
        "\n",
        "Compare model confidence and accuracy on fixed validation subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a06e81de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load holdout predictions\n",
        "holdout_internal = pd.read_csv(INTERNAL_EXP / 'telemetry' / 'holdout_predictions.csv')\n",
        "holdout_external = pd.read_csv(EXTERNAL_EXP / 'telemetry' / 'holdout_predictions.csv')\n",
        "\n",
        "# Get final epoch predictions\n",
        "final_internal = holdout_internal[holdout_internal['epoch'] == holdout_internal['epoch'].max()]\n",
        "final_external = holdout_external[holdout_external['epoch'] == holdout_external['epoch'].max()]\n",
        "\n",
        "# Compute confidence (difference between logits)\n",
        "final_internal['confidence'] = (final_internal['logit_1'] - final_internal['logit_0']).abs()\n",
        "final_external['confidence'] = (final_external['logit_1'] - final_external['logit_0']).abs()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Accuracy over time\n",
        "acc_internal = holdout_internal.groupby('batch_idx')['correct'].mean() * 100\n",
        "acc_external = holdout_external.groupby('batch_idx')['correct'].mean() * 100\n",
        "\n",
        "axes[0, 0].plot(acc_internal.index, acc_internal.values, 'b-o', label='Internal', linewidth=2, markersize=4)\n",
        "axes[0, 0].plot(acc_external.index, acc_external.values, 'r-s', label='External', linewidth=2, markersize=4)\n",
        "axes[0, 0].axhline(y=50, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[0, 0].set_xlabel('Batch Index')\n",
        "axes[0, 0].set_ylabel('Accuracy (%)')\n",
        "axes[0, 0].set_title('Holdout Accuracy Over Training')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Confidence histograms\n",
        "axes[0, 1].hist(final_internal['confidence'], bins=20, alpha=0.5, color='blue', label='Internal', edgecolor='black')\n",
        "axes[0, 1].hist(final_external['confidence'], bins=20, alpha=0.5, color='red', label='External', edgecolor='black')\n",
        "axes[0, 1].set_xlabel('Confidence (|logit1 - logit0|)')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('Prediction Confidence (Final Epoch)')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Confidence vs correctness\n",
        "axes[1, 0].scatter(final_internal['confidence'], final_internal['correct'], alpha=0.5, c='blue', label='Internal', s=50)\n",
        "axes[1, 0].scatter(final_external['confidence'], final_external['correct'], alpha=0.5, c='red', label='External', s=50, marker='s')\n",
        "axes[1, 0].set_xlabel('Confidence')\n",
        "axes[1, 0].set_ylabel('Correct (0 or 1)')\n",
        "axes[1, 0].set_title('Confidence vs Correctness')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Label distribution in holdout\n",
        "internal_label_dist = final_internal['label'].value_counts()\n",
        "external_label_dist = final_external['label'].value_counts()\n",
        "\n",
        "x = [0, 1]\n",
        "axes[1, 1].bar([i - 0.2 for i in x], [internal_label_dist.get(i, 0) for i in x], width=0.4, color='blue', alpha=0.7, label='Internal Labels')\n",
        "axes[1, 1].bar([i + 0.2 for i in x], [external_label_dist.get(i, 0) for i in x], width=0.4, color='red', alpha=0.7, label='External Labels')\n",
        "axes[1, 1].set_xlabel('Label (0 or 1)')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "axes[1, 1].set_title('Holdout Label Distribution')\n",
        "axes[1, 1].set_xticks(x)\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final holdout metrics:\")\n",
        "print(f\"  Internal: accuracy={final_internal['correct'].mean()*100:.1f}%, avg_confidence={final_internal['confidence'].mean():.3f}\")\n",
        "print(f\"  External: accuracy={final_external['correct'].mean()*100:.1f}%, avg_confidence={final_external['confidence'].mean():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8713b1ec",
      "metadata": {},
      "source": [
        "## 5. Summary & Conclusions\n",
        "\n",
        "Key findings from the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5641c54",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"SUMMARY OF FINDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. TRAINING PERFORMANCE:\")\n",
        "print(f\"   Internal: {internal_history['val_acc'][-1]:.1f}% validation accuracy\")\n",
        "print(f\"   External: {external_history['val_acc'][-1]:.1f}% validation accuracy\")\n",
        "print(f\"   Gap: {external_history['val_acc'][-1] - internal_history['val_acc'][-1]:.1f} percentage points\")\n",
        "\n",
        "print(\"\\n2. LABEL DISTRIBUTION BIAS:\")\n",
        "internal_bias = batch_internal['winner_1_pct'].mean() - 50\n",
        "external_bias = batch_external['winner_1_pct'].mean() - 50\n",
        "print(f\"   Internal: {internal_bias:+.1f}% bias (mean winner=1: {batch_internal['winner_1_pct'].mean():.1f}%)\")\n",
        "print(f\"   External: {external_bias:+.1f}% bias (mean winner=1: {batch_external['winner_1_pct'].mean():.1f}%)\")\n",
        "\n",
        "if abs(external_bias) > 10:\n",
        "    print(f\"   âš ï¸ External has SIGNIFICANT {external_bias:+.1f}% bias toward winner=1!\")\n",
        "    print(f\"   This makes the learning task easier and inflates accuracy.\")\n",
        "\n",
        "print(\"\\n3. GRADIENT NORMS:\")\n",
        "print(f\"   Internal: {grad_internal['overall'].mean():.4f} (overall)\")\n",
        "print(f\"   External: {grad_external['overall'].mean():.4f} (overall)\")\n",
        "print(f\"   Difference: {abs(grad_internal['overall'].mean() - grad_external['overall'].mean()):.4f}\")\n",
        "\n",
        "print(\"\\n4. MODEL CONFIDENCE:\")\n",
        "print(f\"   Internal: {final_internal['confidence'].mean():.3f} (avg confidence)\")\n",
        "print(f\"   External: {final_external['confidence'].mean():.3f} (avg confidence)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CONCLUSION:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if abs(external_bias) > 10:\n",
        "    print(\"\\nðŸ”´ ROOT CAUSE: External dataloader has BIASED labels!\")\n",
        "    print(f\"   External has {external_bias:+.1f}% bias toward winner=1\")\n",
        "    print(f\"   This makes it easier to achieve high accuracy by learning the bias\")\n",
        "    print(f\"   rather than actual image quality differences.\")\n",
        "    print(\"\\n   Internal uses balanced data â†’ harder task â†’ appears to underperform\")\n",
        "    print(\"   But internal is actually learning the CORRECT task!\")\n",
        "else:\n",
        "    print(\"\\nðŸŸ¡ Labels appear balanced. Further investigation needed:\")\n",
        "    print(\"   - Check transform differences\")\n",
        "    print(\"   - Analyze weight evolution\")\n",
        "    print(\"   - Compare error patterns\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
