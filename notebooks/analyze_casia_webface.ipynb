{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASIA-WebFace Dataset Analysis\n",
    "\n",
    "Explore the CASIA-WebFace face recognition dataset.\n",
    "\n",
    "- ~494K face images\n",
    "- 10,572 unique identities\n",
    "- 112x112 aligned face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR = Path(r'D:/DataSets/casia_Webface')\n",
    "IMAGES_DIR = DATASET_DIR / 'images'\n",
    "LST_PATH = DATASET_DIR / 'casia-webface' / 'train.lst'\n",
    "\n",
    "print(f\"Dataset directory: {DATASET_DIR}\")\n",
    "print(f\"Images directory: {IMAGES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset Metadata\n",
    "\n",
    "First, let's parse the .lst file to understand the dataset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the .lst file directly (no extraction needed for analysis)\n",
    "print(\"Parsing train.lst file...\")\n",
    "\n",
    "samples = []\n",
    "with open(LST_PATH, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) >= 3:\n",
    "            idx = int(parts[0])\n",
    "            original_path = parts[1]\n",
    "            label = int(parts[2])\n",
    "            # Extract person ID from path\n",
    "            person_id = original_path.split('/')[-2]\n",
    "            image_name = original_path.split('/')[-1]\n",
    "            \n",
    "            # Parse bounding box if available\n",
    "            bbox = None\n",
    "            if len(parts) >= 7:\n",
    "                bbox = [float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])]\n",
    "            \n",
    "            samples.append({\n",
    "                'idx': idx,\n",
    "                'label': label,\n",
    "                'person_id': person_id,\n",
    "                'image_name': image_name,\n",
    "                'bbox': bbox\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(samples)\n",
    "print(f\"Total images: {len(df):,}\")\n",
    "print(f\"Unique identities: {df['label'].nunique():,}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images per identity\n",
    "images_per_identity = df.groupby('label').size()\n",
    "\n",
    "print(\"Images per Identity Statistics:\")\n",
    "print(f\"  Min:    {images_per_identity.min()}\")\n",
    "print(f\"  Max:    {images_per_identity.max()}\")\n",
    "print(f\"  Mean:   {images_per_identity.mean():.1f}\")\n",
    "print(f\"  Median: {images_per_identity.median():.1f}\")\n",
    "print(f\"  Std:    {images_per_identity.std():.1f}\")\n",
    "\n",
    "# Distribution plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax = axes[0]\n",
    "ax.hist(images_per_identity, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(images_per_identity.mean(), color='red', linestyle='--', label=f'Mean: {images_per_identity.mean():.1f}')\n",
    "ax.axvline(images_per_identity.median(), color='orange', linestyle='--', label=f'Median: {images_per_identity.median():.1f}')\n",
    "ax.set_xlabel('Images per Identity')\n",
    "ax.set_ylabel('Number of Identities')\n",
    "ax.set_title('Distribution of Images per Identity')\n",
    "ax.legend()\n",
    "\n",
    "# Top identities\n",
    "ax = axes[1]\n",
    "top_20 = images_per_identity.nlargest(20)\n",
    "ax.barh(range(20), top_20.values)\n",
    "ax.set_yticks(range(20))\n",
    "ax.set_yticklabels([f'ID {i}' for i in top_20.index])\n",
    "ax.set_xlabel('Number of Images')\n",
    "ax.set_title('Top 20 Identities by Image Count')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. View 3 Random People\n",
    "\n",
    "Let's visualize images from 3 randomly selected identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if images are extracted, otherwise use RecordIO directly\n",
    "use_extracted = IMAGES_DIR.exists() and any(IMAGES_DIR.iterdir())\n",
    "\n",
    "if use_extracted:\n",
    "    print(\"Using extracted images from:\", IMAGES_DIR)\n",
    "else:\n",
    "    print(\"Images not extracted. Will extract on-the-fly from RecordIO.\")\n",
    "    print(\"Run: python -m sim_bench.datasets.casia.extract_casia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_recordio(rec_path, idx_path, image_idx):\n",
    "    \"\"\"\n",
    "    Load a single image from RecordIO without extracting all.\n",
    "    \"\"\"\n",
    "    import struct\n",
    "    from io import BytesIO\n",
    "    \n",
    "    # Read index\n",
    "    idx_map = {}\n",
    "    with open(idx_path, 'rb') as f:\n",
    "        while True:\n",
    "            data = f.read(16)\n",
    "            if len(data) < 16:\n",
    "                break\n",
    "            key, offset = struct.unpack('QQ', data)\n",
    "            idx_map[key] = offset\n",
    "    \n",
    "    if image_idx not in idx_map:\n",
    "        return None\n",
    "    \n",
    "    with open(rec_path, 'rb') as f:\n",
    "        f.seek(idx_map[image_idx])\n",
    "        \n",
    "        # Read header\n",
    "        header = f.read(8)\n",
    "        flag, length = struct.unpack('II', header)\n",
    "        \n",
    "        # Read data\n",
    "        data = f.read(length)\n",
    "        \n",
    "        # Find image start (JPEG magic bytes)\n",
    "        jpeg_start = data.find(b'\\xff\\xd8\\xff')\n",
    "        if jpeg_start >= 0:\n",
    "            img_data = data[jpeg_start:]\n",
    "            return Image.open(BytesIO(img_data))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def load_images_for_identity(label, df, max_images=8):\n",
    "    \"\"\"\n",
    "    Load images for a specific identity.\n",
    "    \"\"\"\n",
    "    person_samples = df[df['label'] == label].head(max_images)\n",
    "    images = []\n",
    "    \n",
    "    if use_extracted:\n",
    "        # Load from extracted files\n",
    "        person_dir = IMAGES_DIR / 'images' / f'id_{label:05d}'\n",
    "        if person_dir.exists():\n",
    "            for img_path in sorted(person_dir.glob('*.jpg'))[:max_images]:\n",
    "                img = Image.open(img_path)\n",
    "                images.append(img)\n",
    "    else:\n",
    "        # Load from RecordIO\n",
    "        rec_path = DATASET_DIR / 'casia-webface' / 'train.rec'\n",
    "        idx_path = DATASET_DIR / 'casia-webface' / 'train.idx'\n",
    "        \n",
    "        for _, row in person_samples.iterrows():\n",
    "            img = load_image_from_recordio(rec_path, idx_path, row['idx'])\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    \n",
    "    return images, person_samples['person_id'].iloc[0] if len(person_samples) > 0 else 'Unknown'\n",
    "\n",
    "\n",
    "# Select 3 random identities with at least 5 images\n",
    "identities_with_enough = images_per_identity[images_per_identity >= 5].index.tolist()\n",
    "selected_identities = random.sample(identities_with_enough, 3)\n",
    "\n",
    "print(f\"Selected identities: {selected_identities}\")\n",
    "print(f\"Images per identity: {[images_per_identity[i] for i in selected_identities]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images for each selected identity\n",
    "fig, axes = plt.subplots(3, 8, figsize=(16, 7))\n",
    "\n",
    "for row_idx, identity in enumerate(selected_identities):\n",
    "    images, person_id = load_images_for_identity(identity, df, max_images=8)\n",
    "    \n",
    "    for col_idx in range(8):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "        \n",
    "        if col_idx < len(images):\n",
    "            ax.imshow(images[col_idx])\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel(f'ID: {identity}\\n({person_id})', fontsize=10)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        if row_idx == 0:\n",
    "            ax.set_title(f'Image {col_idx + 1}', fontsize=9)\n",
    "\n",
    "plt.suptitle('3 Random Identities from CASIA-WebFace', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATASET_DIR / 'sample_identities.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved visualization to: {DATASET_DIR / 'sample_identities.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identity Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize identities by image count\n",
    "bins = [0, 10, 20, 50, 100, 200, 500, 1000]\n",
    "labels = ['1-10', '11-20', '21-50', '51-100', '101-200', '201-500', '500+']\n",
    "\n",
    "binned = pd.cut(images_per_identity, bins=bins, labels=labels, right=True)\n",
    "bin_counts = binned.value_counts().sort_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "bars = ax.bar(bin_counts.index, bin_counts.values, color='steelblue', edgecolor='black')\n",
    "\n",
    "# Add count labels\n",
    "for bar, count in zip(bars, bin_counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "            f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_xlabel('Images per Identity')\n",
    "ax.set_ylabel('Number of Identities')\n",
    "ax.set_title('Identity Distribution by Image Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nIdentity count by images:\")\n",
    "for label, count in bin_counts.items():\n",
    "    print(f\"  {label:>8} images: {count:>5,} identities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CASIA-WebFace Dataset Summary\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total images:        {len(df):>10,}\")\n",
    "print(f\"Unique identities:   {df['label'].nunique():>10,}\")\n",
    "print(f\"Avg images/identity: {len(df) / df['label'].nunique():>10.1f}\")\n",
    "print(f\"Image size:          112 x 112 px\")\n",
    "print(f\"\\nImages per identity:\")\n",
    "print(f\"  Min:    {images_per_identity.min():>6}\")\n",
    "print(f\"  Max:    {images_per_identity.max():>6}\")\n",
    "print(f\"  Mean:   {images_per_identity.mean():>6.1f}\")\n",
    "print(f\"  Median: {images_per_identity.median():>6.1f}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
